
<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiewen Lai</title>

    <meta name="author" content="Jiewen Lai">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="css/stylesheet.css" />
    <link rel="icon" type="img" href="img/hamsa.png">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">

                                <td class="mobile-hidden" style="padding:1%;width:32%;max-width:32%;text-align: center" ;>
                                    <img style="width:60%;max-width:60%" alt="profile photo" src="img/jiewen.png">
                                </td>

                                <td style="padding:2.5%;width:73%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name style="font-size:18px">Jiewen Lai</name> / <name style="font-size:18px; font-family: Source Han Serif SC">Ë≥¥Êç∑Êñá</name>
                                    </p>

                                    <p>
                                        I'm a <a
                                            href="http://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-lai-jiewen"
                                            target="_blank"><b>Research Assistant Professor</b></a> from the <a
                                            href="https://www.ee.cuhk.edu.hk/en-gb/" target="_blank"><b>Dept of Electronic
                                            Engineering</b></a>, The Chinese University of Hong Kong (CUHK). I'm interested in flexible robots,
                                        mechatronics, robot perception, sensorimotor control, virtual environments and
                                        simulations, and robot intelligence.
                                    </p>

                                    <p>
                                        From 2022 to 2023, I was a Postdoctoral Fellow at CUHK working with <a
                                            href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-ren-hongliang"
                                            target="_blank">Prof. Hongliang Ren</a>. I did my PhD at <a href="https://www.polyu.edu.hk/me/" target="_blank">ME@PolyU</a>, where I was advised by <a
                                            href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/chu-kar-hang-henry-dr/"
                                            target="_blank">Dr. Henry K. Chu</a> and <a
                                            href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/cheng-li-prof/"
                                            target="_blank">Prof. Li Cheng</a>.
                                    </p>
                                    
                                    <p style="text-align:center"><i class="material-icons" style="font-size: 14px;">&#xe55f;</i> SHB313 &nbsp;&nbsp;&nbsp;&nbsp; <i class="material-icons" style="font-size: 14px;">&#xe0b0;</i> 3943 4343 &nbsp;&nbsp;&nbsp;&nbsp; <i class="material-icons" style="font-size: 14px;">&#xe0be;</i> jiewen.lai <span style="color: rgb(255, 0, 0);">[√¶]</span> <span style="color: rgb(189, 108, 141);">cuhk.edu.hk</span></p>

                                    <p style="text-align:center">
                                        <!-- <a href="XXXX.pdf">Resume</a> &nbsp/&nbsp -->
                                        <a href="https://scholar.google.com/citations?hl=en&user=t77Gv8kAAAAJ&view_op=list_works&sortby=pubdate"
                                            target="_blank">Google Scholar</a> / <a href="preprint/bio_.txt" target="_blank">Bio</a> 
                                             <!-- <a href="https://www.researchgate.net/profile/Jiewen-Lai"
                                            target="_blank">Research Gate</a> /--> 
                                    </p>
                                </td>

                            </tr>
                        </tbody>
                    </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>News</heading>
                                    <p>
                                        <span style="color: rgb(189, 108, 141);">[06/2025]</span> ‚úçüèª Got GRF 2025/26.<br>
                                        <span style="color: rgb(189, 108, 141);">[05/2025]</span> ‚úçüèª Got the International Research Exploration Seed Grant with <a href="https://profiles.stanford.edu/mark-cutkosky" target="_blank">Prof Mark Cutkosky</a> from Stanford.<br>
                                        <span style="color: rgb(189, 108, 141);">[02/2025]</span> ‚úçüèª Great honor to join <a href="https://www.sciencedirect.com/journal/biomimetic-intelligence-and-robotics" target="_blank"><b>Biomimetic intelligence and Robotics</b></a> (JCR Q1, IF: 5.4) as a Young Editorial Board Member.<br>
                                        <span style="color: rgb(189, 108, 141);">[01/2025]</span> üìù Our work with <a href="https://sucro.sdu.edu.cn/info/1012/1491.htm" target="_blank">Prof Zhe Min</a> (Shandong U) has been accepted by <a href="https://www.nature.com/natrevelectreng/" target="_blank"> <b>Nature Reviews Electrical Engineering</b></a>!<br>
                                        <span style="color: rgb(189, 108, 141);">[08/2024]</span> ‚úçüèª Honored to serve as an Associate Editor for <a
                                            href="https://2025.ieee-icra.org/" target="_blank"><b>ICRA 2025</b></a>.<br>
                                        <span style="color: rgb(189, 108, 141);">[08/2024]</span> ‚úçüèª Received a mini grant from NSFC'24 <a
                                            href="https://www.cpr.cuhk.edu.hk/en/press/25-cuhk-professors-receive-funding-support-from-national-natural-science-foundation-of-china-worth-over-rmb41-million-in-total/" target="_blank"><b>[CUHK Press Release]</b></a>.<br>
                                        <span style="color: rgb(189, 108, 141);">[05/2024]</span> ü§µ Honored to be invited as a speaker for ICRA workshop: <a href="https://events.femto-st.fr/Workshop-ICRA2024-Continuum-Soft-Robotics/en" target="_blank"><b>Continuum and Soft Robotics for Medical Applications with Rising Stars on the Stage</b></a>.<br>
                                        <span style="color: rgb(189, 108, 141);">[01/2024]</span> ‚õ©Ô∏è Our workshop <a href="https://sites.google.com/view/icra24-c4sr/home" target="_blank"> <b>C4SR+</b></a> has been accepted by <a
                                            href="https://2024.ieee-icra.org/" target="_blank"><b>ICRA 2024</b></a>. It will be
                                        held in Yokohama, Japan, in May 2024.<br>
                                        <span style="color: rgb(189, 108, 141);">[10/2023]</span> ‚úçüèª Honored to serve as an Associate Editor for <a
                                            href="https://2024.ieee-icra.org/" target="_blank"><b>ICRA 2024</b></a>.<br>
                                        <span style="color: rgb(189, 108, 141);">[08/2023]</span> üë®üèª‚Äçüè´ I join the faculty board and the electronic engineering dept at
                                        CUHK as a Research Assistant Professor.<br>

                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    
                    <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                               <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Opportunities</heading>
                                    <p>
                                    <div class="content" style="max-height: 290px;">

                                         <p style="color: black;font-size: 14px">
                                           <strong>PhD/MPhil (2026Fall)/Full time RA:</strong> The candidate will work on flexible robots concerning i) sensor-based control, ii) robophysical simulation, iii) teleoperation, iv) robot modeling, or v) VR/XR for robot interaction. For RA, s/he will be expected to work in Hong Kong for at least TEN months. Candidates with DJI-RM / ICRA / VR / robotics-related challenge experience will be a great plus. [Re-post on Jul, 2025] 
                                        </p>

                                        <p style="color: rgb(57, 117, 147);font-size: 14px">
                                            Prospective students from ME/EE/CS/Control/Robotics/Software or related disciplines are welcome to email me. Please note that I may not be able to respond to everyone due to the high volume of emails.
                                        </p>
                                        <p style="color: black;font-size: 14px">Interested candidates are expected to attach the following 3 documents:</p>
                                        <ul style="color: black;font-size: 14px">
                                            <li>
                                                <b>Detailed CV</b>
                                            </li>
                                            <li>
                                                <b>Publications / Writing samples</b> (i.e., PDFs of your papers)
                                            </li>
                                            <li>
                                                <b>Research portfolio</b> (no more than 3 slides demonstrating whatever you like)
                                            </li>
                                        </ul>
                                    </div>
                                    </p>
                               </td> 
                            </tr>
                        </tbody>
                    </table> -->

                    <!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>
                                    Opportunity</heading>
                                <p>
                                    <div class="content" style="max-height: 290px;">
                                        <p style="color: black;font-size: 14px">
                                            Looking for a <b>Full-Time Research Assistant (RA)</b> to work in person at CUHK for 8-10 months, starting from Early 2024. S/he will be responsible for a project related to <i>High Dimensional Data-Driven Soft Robots</i>. This project will primarily involve modeling, ML, simulation, and visual sensing.
                                        </p>
                                        <p style="color:black;font-size: 14px">
                                            Prospective students from ME/EE/CS/Control/Robotics or related disciplines are welcome to email me <mark>(Subject: FTRA-Year of Study-Univ-Major)</mark>. CUHK undergrad students, fresh grads (i.e., you have obtained a bachelor's degree / master's degree), and MS students looking for internship opportunities will be ideal.
                                        </p>
                                        <p style="color: black;font-size: 14px">Interested candidates are expected to attach the following 3 documents:</p>
                                        <ul style="color: black;font-size: 14px">
                                            <li>
                                                <b>Detailed CV</b>
                                            </li>
                                            <li>
                                                <b>Publications</b> (i.e., PDFs of your papers)
                                            </li>
                                            <li>
                                                <b>Research portfolio</b> (no more than 3 slides demonstrating relevant demos/skills)
                                            </li>
                                        </ul>
                                    </div>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>-->


                <div style="margin-top: 1cm;"></div>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Selected Publications</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

                        <tbody>

                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/robot_img.jpg' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="" target="_blank"
                                        <papertitle>Twistable Soft Continuum Robots</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai<sup><small>&#8224;</small></sup></strong>, Yanjun Liu<sup><small>&#8224;</small></sup>, Tian-Ao Ren, Yan Ma, Tao Zhang, Jeremy Teoh, Mark R. Cutkosky, Hongliang Ren*

                                    <br>
                                    <em>Journal</em>, 2025 &nbsp (Under Review)
                                    
                                    <br>
                                    <!-- <a href="preprint/huang-et-el.pdf" target="_blank" class="pdf-button">pdf</a>  -->
                                    <!-- <p>
                                        <strong>tl;dr:</strong> Embodying gravity sensation in soft slender robots with a minimalist setup.
                                    </p> -->
                                </td>
                            </tr>
                            

                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/soro_g.gif' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="" target="_blank"
                                        <papertitle>Gravity-Aware Proactive Joint-Level Compensation for Portable Soft Slender Robots Using A Single IMU and Real-Time Simulation</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai<sup><small>&#8224;</small></sup></strong>, Tian-Ao Ren<sup><small>&#8224;</small></sup>, Pengfei Ye, Yanjun Liu, Jingyao Sun, Hongliang Ren*

                                    <br>
                                    <em>International Journal of Robotics Research (IJRR)</em>, 2026 &nbsp (Accepted)
                                    
                                    <br>
                                    <!-- <a href="preprint/huang-et-el.pdf" target="_blank" class="pdf-button">pdf</a>  -->
                                    <p>
                                        <strong>tl;dr:</strong> Embodying gravity sensation in soft slender robots with a minimalist setup.</p>
                                </td>
                            </tr>
                            
                        

                            
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/Artificial-intelligence-in-health-care-hero-8a35b15aee36fc17e11ee31c08aa0a48.png' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://www.nature.com/articles/s44287-025-00166-6" target="_blank"
                                        <papertitle>Innovating Robot-assisted Surgery through Large Vision Models</papertitle>
                                    </a>
                                    <br>
                                    Zhe Min<sup><small>&#8224;</small></sup>, <strong>Jiewen Lai<sup><small>&#8224;</small></sup></strong>, Hongliang Ren*

                                    <br>
                                    <em>Nature Reviews Electrical Engineering</em>, 2025 &nbsp
                                    <br>
                                    <a href="https://www.nature.com/articles/s44287-025-00166-6" target="_blank" class="video-button">DOI</a>
                                    <a href="https://www.facebook.com/NaturePortfolioJournals/photos/a-perspective-in-nature-reviews-electrical-engineering-discusses-how-large-visio/1156327659856832/?_rdr" target="_blank" class="pdf-button">Reposted by Nature Portfolio</a>
                                    <p>
                                        <strong>tl;dr:</strong> A Perspective in Nature Reviews Electrical Engineering discusses how large vision models can enhance vision-related tasks in robot-assisted surgery transforming ‚Äòsurgical robots‚Äô into ‚Äòrobotic surgeons.‚Äô ‚Äî Nature Portfolio

                                    </p>
                                </td>
                            </tr>                            

                            <!-- Paper 1  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/ami.jpeg' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://pubs.acs.org/doi/10.1021/acsami.4c10675" target="_blank"
                                        <papertitle>Large-Scale Selective Micropatterning with Robotics nDEP Tweezers and Hydrogel Encapsulation</papertitle>
                                    </a>
                                    <br>
                                    Kaicheng Huang, <strong>Jiewen Lai</strong>, Hongliang Ren, Chunhui Wu, Xing Cheng, Henry K. Chu*

                                    <br>
                                    <em>ACS Applied Materials & Interfaces</em>, 2024 &nbsp
                                    <br>
                                    <a href="preprint/huang-et-el.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Patterning micro particles (cells) using negative dielectrophoresis (nDEP) tweezer in batches and encapsulating them into hydrogel for tissue engineering.
                                    </p>
                                </td>
                            </tr>




                            <!-- Paper 1  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/GesSo_demo_5x.gif' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/10505917" target="_blank"
                                        <papertitle>Gesture-based Steering Framework for Redundant Soft Robots</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Bo Lu, Kaicheng Huang, Henry K. Chu*

                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2024 &nbsp
                                    
                                    <br>
                                    <a href="preprint/TMECH_LMC.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/C1NUudoweUs" target="_blank" class="video-button">video</a> 
                                    <a href="https://github.com/samlaipolyu/GesSo" target="_blank" class="code-button">code</a> 
                                    <p>
                                        <strong>tl;dr:</strong> A steering framework for redundant soft manipulators using real-time hand motion and gestures.
                                    </p>
                                </td>
                            </tr>


                            <!-- Paper 1  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sim2real.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/10171986" target="_blank"
                                        <papertitle>Sim-to-Real Transfer of Soft Robotic Navigation Strategies That
                                        Learns from the Virtual Eye-in-Hand Vision</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai<sup><small>&#8224;</small></sup></strong>,
                                    Tian-Ao Ren<sup><small>&#8224;</small></sup></strong>,
                                    Wenchao Yue,
                                    Shijian Su,
                                    Jason Chan,
                                    Hongliang Ren*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Transactions on Industrial Informatics (T-II)</em>, 2023 &nbsp
                                    <br>
                                    <a href="preprint/TII-2024-Sim2Real_compressed.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/vQ4xzFM9iwk" target="_blank" class="video-button">video</a> 
                                    <a href="https://github.com/TeoREN0217/6CablesWithCamera" target="_blank" class="code-button">code</a> 
                                    <a href="https://www.sofa-framework.org/applications/publications/" target="_blank" class="archiv-button">sofa archive</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Transferring the navigation strategy that a redundant
                                        soft robot learns from what it has seen in the SOFA-based virtual world to the real world.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 2  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sam_soroExp.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://www.liebertpub.com/doi/full/10.1089/soro.2021.0179" target="_blank"
                                        <papertitle>Lightweight Pneumatically Elastic Backbone Structure with Modular
                                        Construction and Nonlinear Interaction for Soft Actuators</papertitle>
                                    </a>
                                    <br>
                                    Yang Yang,
                                    <strong>Jiewen Lai</strong>,
                                    Chaochao Xu, Zhiguo He, Pengcheng Jiao, Hongliang Ren*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>Soft Robotics (SoRo)</em>, 2023
                                    <br>
                                    <a href="preprint/soro23.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://www.liebertpub.com/doi/full/10.1089/soro.2021.0179" target="_blank" class="video-button">videos</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Robotizing any strip-shaped balloons with mechanically
                                        programmed 3D-printed shells.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 3  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/soft_sensor.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9633254" target="_blank"
                                        <papertitle>Reconstructing External Force on the Circumferential Body of
                                        Continuum Robot With Embedded Proprioceptive Sensors</papertitle>
                                    </a>
                                    <br>
                                    Qingxiang Zhao,
                                    <strong>Jiewen Lai</strong>,
                                    Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Transactions on Industrial Electronics (T-IE)</em>, 2022
                                    <br>
                                    <a href="preprint/TIE_22.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://ieeexplore.ieee.org/ielx7/41/9970766/9633254/supp1-3130326.mp4?arnumber=9633254" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Endowing proprioception to soft robots with embedded
                                        eGaIn vein through learning.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 4  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/ncc2.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9716747" target="_blank"
                                        <papertitle>Constrained Motion Planning of A Cable-Driven Soft Robot with
                                        Compressible Curvature Modeling</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Bo Lu,
                                    Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2022
                                    <br>
                                    <a href="preprint/10.1109@LRA.2022.3152318.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/Zb3cA3hTvKgE" target="_blank" class="video-button">video1</a> 
                                    <a href="https://youtu.be/CfRrfUAi4aQ" target="_blank" class="video-button">video2</a> 
                                    <a href="https://github.com/samlaipolyu/ncc_motion_planning"
                                        target="_blank" class="code-button">code</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Tip pose and whole-body motion planning of a 7-DOF soft
                                        robot in constrained environments considering the cable-driven-induced length
                                        change of its soft body.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 5  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/stiffness.png' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9427246" target="_blank"
                                        <papertitle>Variable-Stiffness Control of A Dual-Segment Soft Robot using Depth
                                        Vision</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Bo Lu, Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2021
                                    <br>
                                    <a href="preprint/TMECH_VS.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/QMHYsExF1JE" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Controlling the soft robot's 3D motion & stiffness in
                                        real time with antagonistic cable actuation strategy based on eye-to-hand depth vision.
                                    </p>
                                </td>
                            </tr>


                            <!-- Paper 6  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sucks.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9462388" target="_blank"
                                        <papertitle>Verticalized-Tip Trajectory Tracking of A 3D-Printable Soft
                                        Continuum Robot: Enabling Surgical Blood Suction Automation</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, Bo Lu, Qingxiang Zhao, Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2021
                                    <br>
                                    <a href="preprint/TMECH_VT.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/_5zb7vnvwkA" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Configuration constraints on a redundant soft robot,
                                        with rapid IK, solved through point cloud projection and image-based liquid
                                        suction planning.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 7  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/aim_demo.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9158975" target="_blank"
                                        <papertitle>Toward Vision-based Adaptive Configuring of A Bidirectional
                                        Two-Segment Soft Continuum Manipulator</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, Bo Lu, and Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics
                                        (AIM)</em>, 2020
                                    <br>
                                    <a href="preprint/10.1109@AIM43001.2020.9158975.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/_yy3LjOx5cc" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Steering  and servoing a two-segment soft robot's 2D pose with eye-to-hand vision in real-time - regardless of the static payload.
                                    </p>
                                </td>
                            </tr>

                            
                            <!-- Paper 8  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/robio.png' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/8961669" target="_blank"
                                        <papertitle>A Learning-based Inverse Kinematics Solver for a Multi-Segment Continuum Robot in Robot-Independent Mapping</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, and Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE International Conference on Robotics and Biomimetics (ROBIO)</em>, 2019
                                    <br>
                                    <a href="preprint/ROBIO_19.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://github.com/jiewen-lai/iksolver_mlx_robio19" target="_blank" class="code-button">code</a> 
                                    <a href="https://research.polyu.edu.hk/en/prizes/best-paper-finalist" target="_blank" class="award-button">best paper finalist award</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Utilizing a lightweight MLP model to learn a redundant soft robot's IK through its simplified DH model.
                                    </p>
                                </td>
                            </tr>



                        </tbody>
                    </table>

                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Research Grants</heading>
                                <p>

                                <li>
                                    <b>General Research Fund</b>, Research Grants Council<br>
                                    <i>&ensp;&ensp;&ensp;"CryroFR"</i><br>
                                    &ensp;&ensp;&ensp;PI, HKD 1.1M, 2026 to 2028. 
                                </li>

                                <br>   

                                <li>
                                    <b>International Research Exploration Seed Grant</b>, Stanford University<br>
                                    <i>&ensp;&ensp;&ensp;"Gecko-inspired variable stiffness flexible robot"</i><br>
                                    &ensp;&ensp;&ensp;Co-PI, USD 25K, 2026 to 2027.<br>
                                    &ensp;&ensp;&ensp;PI: Prof. Mark R. Cutkosky (Fletcher Jones Professor, Dept of Mechanical Engineering, Stanford University)
                                </li>

                                <br>   

                                 <li>
                                    <b>General Program - Guangdong Natural Science Fund</b>, Guangdong Basic and Applied Basic Research Foundataion<br>
                                    <i>&ensp;&ensp;&ensp;"Soft Robophysical Simulation"</i><br>
                                    &ensp;&ensp;&ensp;PI, CNY 100K, 2025 to 2028. 
                                </li>

                                <br>
                                
                                <li>
                                    <b>Young Scientists Fund</b>, Natural Science Foundation of China (NSFC)<br>
                                    <i>&ensp;&ensp;&ensp;Coupled Tendon-driven Continuum Robots for R-MIS</i><br>
                                    &ensp;&ensp;&ensp;PI, CNY 300K, 2025-01 to 2027-12. 
                                </li>

                                <br>

                                <li>
                                    <b>Direct Grant</b>, CUHK Research Committee<br>
                                    <i>&ensp;&ensp;&ensp;Flexible Endoscopic Robots for Transluminal-Submucosal Drug Delivery</i><br>
                                    &ensp;&ensp;&ensp;PI, 2024-01 to 2025-12.
                                </li>

                                <br>

                                <li>
                                    <b>IdeaBooster Fund Award</b>, Venture Acceleration Office, CUHK InnoPort<br>
                                    <i>&ensp;&ensp;&ensp;"Miniature Notched Tubular Soft Robots"</i><br>
                                    &ensp;&ensp;&ensp;PI, HKD 100K, 2023-06 to 2024-12 (Completed).
                                </li>

                                <br>
<!-- 
                                 -->

                                
                                </p>
                            </td>
                        </tr>
                    </tbody>
                    </table>                   

                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Professional Memberships</heading>
                                <p>
                                    Senior Member, Chinese Mechanical Engineering Society (CMES)<br />
                                    Member, IEEE Robotics and Automation Society (RAS)<br />
                                    Member, Chinese Association of Automation (CAA)
                                </p>
                            </td>
                        </tr>
                    </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Professional Services</heading>
                                    <p>
                                        <b>Associate Editor (AE)</b>: <a href="https://2026.ieee-icra.org/" target="_blank">ICRA'26</a>, <a href="https://2025.ieee-icra.org/" target="_blank">ICRA'25</a>, <a href="https://2024.ieee-icra.org/" target="_blank">ICRA'24</a><br/>
                                        <b>Workshop Organizer</b><br/>
                                        &ensp;&ensp;&ensp;&ensp; - <a href="https://sites.google.com/view/iros-2025-c4sr/home" target="_blank"><b>The 3rd C<sup><small>4</small></sup>SR+</b> workshop</a> at IROS 2025<br/>

                                        &ensp;&ensp;&ensp;&ensp; - <a href="https://sites.google.com/view/icra24-c4sr" target="_blank"><b>The 2nd C<sup><small>4</small></sup>SR+</b> workshop</a> at ICRA 2024<br/>

                                        <b>Guest Editor</b>: <a href="https://www.oaepublish.com/specials/ir.10231" target="_blank">Intelligence & Robotics</a>, <a href="https://www.mdpi.com/journal/actuators/special_issues/808GZE9H7Y" target="_blank">Actuators</a><br/>
                                        <b>Reviewer</b>: <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8860" target="_blank">T-RO</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=3516" target="_blank">T-MECH</a>, <a href="https://www.ieee-ras.org/publications/ra-l" target="_blank">RA-L</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9424" target="_blank">T-II</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=41" target="_blank">T-IE</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8856" target="_blank">T-ASE</a>, <a href="https://ieeeaccess.ieee.org/" target="_blank">IEEE Access</a>, </a><a href="https://onlinelibrary.wiley.com/journal/15564967" target="_blank">JFR</a>, <a href="https://www.springer.com/journal/11071" target="_blank">Nonlinear Dyn</a>, <a href="https://onlinelibrary.wiley.com/journal/1478596X" target="_blank">IJMRCAS</a>, <a href="https://www.sciencedirect.com/journal/biomimetic-intelligence-and-robotics" target="_blank">Biomim Intell Robot</a>, <a href="https://www.mdpi.com/journal/sensors" target="_blank">Sensors</a><br/>
                                        <b>Reviewer for conferences</b>: <a href="https://www.ieee-ras.org/conferences-workshops" target="_blank">ICRA'26, IROS'25, ICRA'25, ICSR'24, IROS'24, RCAR'24, ICRA'24, RoboSoft'23, ARM'22, ICRA'22, ICRA'21, ICAR'21, AIM'20, CASE'20, IROS'19, ROBIO'19</a><br/>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

      

                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Teaching</heading>
                                <p>
                                    <a href="https://www.ee.cuhk.edu.hk/en-gb/curriculum/undergraduate-programme/course-list#Major_Elective_Courses" target="_blank"><b>ELEG4701</b> Intelligent Interactive Robot Practice</a> (24'Spring, 24'Fall, 25'Fall) <br>
                                    <!-- <a href="preprint/Lab_6__ROS_Navigation___Slides.pdf" target="_blank" class="pdf-button">Lecture 6</a>
                                    <a href="preprint/Lab_9__VS_for_Mobile_Robots.pdf" target="_blank" class="pdf-button">Lecture 9</a>
                                    <a href="preprint/Lab_10__Intro_to_Robot_Arm___Slides.pdf" target="_blank" class="pdf-button">Lecture 10</a> <br> -->
                                    <a href="https://www.ee.cuhk.edu.hk/en-gb/133-curriculum/undergraduate-programmes/course-list/major-required-courses/754-eleg4998-final-year-project-i" target="_blank"><b>ELEG4998 </b> Final Year Project I</a><br>
                                    <a href="https://www.ee.cuhk.edu.hk/en-gb/133-curriculum/undergraduate-programmes/course-list/major-required-courses/755-eleg4999-final-year-project-ii" target="_blank"><b>ELEG4999 </b> Final Year Project II</a><br>
                                    
                                </p>
                            </td>
                            
                        </tr>
                    </tbody>
                    </table>

<!-- 
                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Some Links</heading>
                                <p>
                                    <a href="http://www.labren.org/mm/" target="_blank"><b>Medical Mechatronics Lab</b></a>, CUHK<br>
                                    <a href="https://www.ucsdarclab.com/" target="_blank"><b>Advanced Robotics and Controls Lab</b></a>, UCSD<br>
                                    <a href="https://hkpfs.erg.cuhk.edu.hk/" target="_blank"><b>Hong Kong PhD Fellowship Summer Workshop</b></a>, Faculty of Engineering, CUHK<br>
                                    <a href="https://link.springer.com/content/pdf/10.1007%2F978-1-84628-642-1.pdf" target="_blank"><b>Robotics: Modelling, Planning and Control</b></a>, Bruno Siciliano et al., Springer's Online Textbook<br>
                                </p>
                            </td>
                            
                        </tr>
                    </tbody>
                    </table> -->

    <!-- Binance API -->
    <!--<script src="js/binanceAPI.js"></script>-->
    <script>
        function toDecimal2(x) {
            var f = parseFloat(x);
            if (isNaN(f)) {
                return false;
            }
            var f = Math.round(x * 100) / 100;
            var s = f.toString();
            var rs = s.indexOf('.');
            if (rs < 0) {
                rs = s.length;
                s += '.';
            }
            while (s.length <= rs + 2) {
                s += '0';
            }
            return s;
        }

        function toDecimal4(x) {
            var f = parseFloat(x);
            if (isNaN(f)) {
                return false;
            }
            var f = Math.round(x * 10000) / 10000;
            var s = f.toString();
            var rs = s.indexOf('.');
            if (rs < 0) {
                rs = s.length;
                s += '.';
            }
            while (s.length <= rs + 4) {
                s += '0';
            }
            return s;
        }

        var js = document.createElement('script');

        js.onload = function () {
            var p = $("<p id='coin'></p>");

            $(document.body).append(p);

            setInterval(function () {
                $.get("https://api.binance.com/api/v3/ticker/24hr").done(function (data) {
                    /* https://bitpay.com/api/rates */
                    /* https://api.binance.com/api/v3/ticker/price */ /* doesnt work in mainland China */

                    var btc = data[11]
                    var doge = data[558]
                    var eth = data[12]
                    /*  11 and 558 and 12*//////  * 2 52 13/

                    let position = toDecimal2((btc.lastPrice * 0.00396395) * 7.82);
                    let result = position.fontcolor("white");

                    /*  $("#coin").html(" " + (new Date()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) + " | <b>BTC/USD: </b>" + toDecimal2(btc.rate) + " | <b>ETH/USD: </b>" + toDecimal2(btc.rate/eth.rate) + " | <b>DOGE/USD: </b>" + toDecimal4(btc.rate/doge.rate));*/

                    $("#coin").html(" " + (new Date()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) + " | <b>BTC/USDT: </b>" + toDecimal2(btc.lastPrice) + " (" + toDecimal2(btc.priceChangePercent) + "%/24hrs)" + " | " + position);
                });
            }, 5000);

        }
                js.src = "//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js";
                document.head.appendChild(js);
        </script>
            <p><a href="https://bitpay.com/api/rates" target="_blank"><img src="img/btc.png" height="16" /></a> <b>Your local time: </b><p id="coin" style="display: inherit; white-space: nowrap;" align="justify"></p></p>
            <p><small><center><a href="https://jonbarron.info" target="_blank">Thanks for the template</a></center></small></p>

            <p><center><script type="text/javascript" src="//rf.revolvermaps.com/0/0/3.js?i=5tffielz35a&amp;b=0&amp;s=40&amp;m=0&amp;cl=ffffff&amp;co=193e68&amp;cd=bd6c8d&amp;v0=40&amp;v1=100&amp;r=1" async="async"></script></center></p>
            <!-- <p><center><a href="https://visitorbadge.io/status?path=samlai.me"><img src="https://api.visitorbadge.io/api/visitors?path=samlai.me&labelColor=%23193e68&countColor=%23bd6c8d&style=flat&labelStyle=none" /></a></center></p> -->
                </td>
            
            </tr>
    </table>
</body>

</html>