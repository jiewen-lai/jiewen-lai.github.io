<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiewen Lai</title>

    <meta name="author" content="Jiewen Lai">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="css/stylesheet.css" />
    <link rel="icon" type="image/png" href="images/RoboNLP.png">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">

                                <td class="mobile-hidden" style="padding:1%;width:32%;max-width:32%;text-align: center" ;>
                                    <img style="width:60%;max-width:60%" alt="profile photo" src="img/jiewen.png">
                                </td>

                                <td style="padding:2.5%;width:73%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name style="font-size:18px">Jiewen Lai</name> / <name style="font-size:18px; font-family: Source Han Serif SC">Ë≥¥Êç∑Êñá</name>
                                    </p>

                                    <p>
                                        I am a <a
                                            href="http://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-lai-jiewen"
                                            target="_blank"><b>Research Assistant Professor</b></a> from the <a
                                            href="https://www.ee.cuhk.edu.hk/en-gb/" target="_blank"><b>Dept of Electronic
                                            Engineering</b></a>, The Chinese University of Hong Kong (CUHK). I'm interested in flexible robots,
                                        mechatronics, robot perception, sensorimotor control, virtual environments and
                                        simulations, and robot intelligence.
                                    </p>

                                    <p>
                                        From 2022 to 2023, I was a Postdoctoral Fellow at CUHK working with <a
                                            href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-ren-hongliang"
                                            target="_blank">Prof. Hongliang Ren</a>. Before that, I received my PhD
                                        degree in <a href="https://www.polyu.edu.hk/me/" target="_blank">Mechanical Engineering</a> at The Hong Kong Polytechnic University in 2022
                                        under the supervision of <a
                                            href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/chu-kar-hang-henry-dr/"
                                            target="_blank"> Ir. Dr. Henry K. Chu</a> and <a
                                            href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/cheng-li-prof/"
                                            target="_blank">Prof. Li Cheng</a>.
                                    </p>
                                    
                                    <p style="text-align:center"><i class="material-icons" style="font-size: 14px;">&#xe55f;</i> SHB313 &nbsp;&nbsp;&nbsp;&nbsp; <i class="material-icons" style="font-size: 14px;">&#xe0b0;</i> 3943 4343 &nbsp;&nbsp;&nbsp;&nbsp; <i class="material-icons" style="font-size: 14px;">&#xe0be;</i> jiewen.lai <span style="color: rgb(255, 0, 0);">[√¶]</span> <span style="color: rgb(189, 108, 141);">cuhk.edu.hk</span></p>

                                    <p style="text-align:center">
                                        <!-- <a href="XXXX.pdf">Resume</a> &nbsp/&nbsp -->
                                        <a href="https://scholar.google.com/citations?hl=en&user=t77Gv8kAAAAJ&view_op=list_works&sortby=pubdate"
                                            target="_blank">Google Scholar</a> / <a href="https://www.researchgate.net/profile/Jiewen-Lai"
                                            target="_blank">Research Gate</a> 
                                    </p>
                                </td>

                            </tr>
                        </tbody>
                    </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>News</heading>
                                    <p>
                                        <span style="color: rgb(189, 108, 141);">[May 2024]</span> ü§µ Honored to be invited as a speaker for ICRA workshop: <a href="https://events.femto-st.fr/Workshop-ICRA2024-Continuum-Soft-Robotics/en" target="_blank"><b>Continuum and Soft Robotics for Medical Applications with Rising Stars on the Stage</b></a>.<br>
                                        <span style="color: rgb(189, 108, 141);">[Mar 2024]</span> üìù Our paper on <a href="preprint/ARSO24_0043_MS.pdf" target="_blank">Sim2Real-RL soft robotic navigation</a> has been accepted by <a
                                        href="https://ieee-arso.org/" target="_blank"><b>ARSO 2024</b></a> to be held in Hong Kong.<br>
                                        <span style="color: rgb(189, 108, 141);">[Jan 2024]</span> ‚õ©Ô∏è Our workshop <a href="https://sites.google.com/view/icra24-c4sr/home" target="_blank"> <b>C4SR+</b></a> has been accepted by <a
                                            href="https://2024.ieee-icra.org/" target="_blank"><b>ICRA 2024</b></a>. It will be
                                        held in Yokohama, Japan, in May 2024.<br>
                                        <span style="color: rgb(189, 108, 141);">[Oct 2023]</span> ‚úçüèª Honored to serve as an Associate Editor for <a
                                            href="https://2024.ieee-icra.org/" target="_blank"><b>ICRA 2024</b></a> - and I rejected half of the papers...<br>
                                        <span style="color: rgb(189, 108, 141);">[Aug 2023]</span> üë®üèª‚Äçüè´ I join the faculty board and the Electronic Engineering Dept of
                                        CUHK as a Research Assistant Professor.<br>

                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    
                    

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>
                                    Opportunity</heading>
                                <p>
                                    <div class="content" style="max-height: 290px;">
                                        <p style="color: black;font-size: 14px">
                                            Looking for a <b>Full-Time Research Assistant (RA)</b> to work in person at CUHK for 8-10 months, starting from Early 2024. S/he will be responsible for a project related to <i>High Dimensional Data-Driven Soft Robots</i>. This project will primarily involve modeling, ML, simulation, and visual sensing.
                                        </p>
                                        <p style="color:black;font-size: 14px">
                                            Prospective students from ME/EE/CS/Control/Robotics or related disciplines are welcome to email me <mark>(Subject: FTRA-Year of Study-Univ-Major)</mark>. CUHK undergrad students, fresh grads (i.e., you have obtained a bachelor's degree / master's degree), and MS students looking for internship opportunities will be ideal.
                                        </p>
                                        <p style="color: black;font-size: 14px">Interested candidates are expected to attach the following 3 documents:</p>
                                        <ul style="color: black;font-size: 14px">
                                            <li>
                                                <b>Detailed CV</b>
                                            </li>
                                            <li>
                                                <b>Publications</b> (i.e., PDFs of your papers)
                                            </li>
                                            <li>
                                                <b>Research portfolio</b> (no more than 3 slides demonstrating relevant demos/skills)
                                            </li>
                                        </ul>
                                    </div>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>


                <div style="margin-top: 1cm;"></div>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

                        <tbody>

                            <!-- Paper 1  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td tyle="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/GesSo_demo_5x.gif' width="180">
                                </td>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <a href="" target="_blank"
                                        <papertitle>Gesture-based Steering Framework for Redundant Soft Robots</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    <a href="https://lu-bo.github.io/" target="_blank">Bo Lu</a>, Kaicheng Huang, Henry K. Chu*

                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2024 &nbsp
                                    
                                    <br>
                                    <a href="preprint/TMECH_LMC.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/C1NUudoweUs" target="_blank" class="video-button">video</a> 
                                    <a href="https://github.com/samlaipolyu/GesSo" target="_blank" class="code-button">code</a> 
                                    <p>
                                        <strong>tl;dr:</strong> A steering framework for redundant soft manipulators using real-time hand motion and gestures.
                                    </p>
                                </td>
                            </tr>


                            <!-- Paper 1  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sim2real.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/10171986" target="_blank"
                                        <papertitle>Sim-to-Real Transfer of Soft Robotic Navigation Strategies That
                                        Learns from the Virtual Eye-in-Hand Vision</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai<sup><small>&#8224;</small></sup></strong>,
                                    <a href="https://teoren0217.github.io/" target="_blank">Tian-Ao Ren<sup><small>&#8224;</small></sup></a>,
                                    Wenchao Yue,
                                    Shijian Su,
                                    Jason Chan,
                                    Hongliang Ren*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Transactions on Industrial Informatics (T-II)</em>, 2023 &nbsp
                                    <br>
                                    <a href="preprint/TII-2024-Sim2Real_compressed.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/vQ4xzFM9iwk" target="_blank" class="video-button">video</a> 
                                    <a href="https://github.com/TeoREN0217/6CablesWithCamera" target="_blank" class="code-button">code</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Transferring the navigation strategy that a redundant
                                        soft robot learns from what it has seen in the SOFA-based virtual world to the real world.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 2  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sam_soroExp.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://www.liebertpub.com/doi/full/10.1089/soro.2021.0179" target="_blank"
                                        <papertitle>Lightweight Pneumatically Elastic Backbone Structure with Modular
                                        Construction and Nonlinear Interaction for Soft Actuators</papertitle>
                                    </a>
                                    <br>
                                    Yang Yang,
                                    <strong>Jiewen Lai</strong>,
                                    Chaochao Xu, Zhiguo He, Pengcheng Jiao, Hongliang Ren*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>Soft Robotics (SoRo)</em>, 2023
                                    <br>
                                    <a href="preprint/soro23.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://www.liebertpub.com/doi/full/10.1089/soro.2021.0179" target="_blank" class="video-button">videos</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Robotizing any strip-shaped balloons with mechanically
                                        programmed 3D-printed shells.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 3  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/soft_sensor.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9633254" target="_blank"
                                        <papertitle>Reconstructing External Force on the Circumferential Body of
                                        Continuum Robot With Embedded Proprioceptive Sensors</papertitle>
                                    </a>
                                    <br>
                                    Qingxiang Zhao,
                                    <strong>Jiewen Lai</strong>,
                                    Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Transactions on Industrial Electronics (T-IE)</em>, 2022
                                    <br>
                                    <a href="preprint/TIE_22.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://ieeexplore.ieee.org/ielx7/41/9970766/9633254/supp1-3130326.mp4?arnumber=9633254" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Endowing proprioception to soft robots with embedded
                                        eGaIn vein through learning.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 4  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/ncc2.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9716747" target="_blank"
                                        <papertitle>Constrained Motion Planning of A Cable-Driven Soft Robot with
                                        Compressible Curvature Modeling</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    <a href="https://lu-bo.github.io/" target="_blank">Bo Lu</a>,
                                    Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2022
                                    <br>
                                    <a href="preprint/10.1109@LRA.2022.3152318.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/Zb3cA3hTvKgE" target="_blank" class="video-button">video1</a> 
                                    <a href="https://youtu.be/CfRrfUAi4aQ" target="_blank" class="video-button">video2</a> 
                                    <a href="https://github.com/samlaipolyu/ncc_motion_planning"
                                        target="_blank" class="code-button">code</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Tip pose and whole-body motion planning of a 7-DOF soft
                                        robot in constrained environments considering the cable-driven-induced length
                                        change of its soft body.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 5  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/stiffness.png' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9427246" target="_blank"
                                        <papertitle>Variable-Stiffness Control of A Dual-Segment Soft Robot using Depth
                                        Vision</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    <a href="https://lu-bo.github.io/" target="_blank">Bo Lu</a>, Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2021
                                    <br>
                                    <a href="preprint/TMECH_VS.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/QMHYsExF1JE" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Controlling the soft robot's 3D motion & stiffness in
                                        real time with antagonistic cable actuation strategy based on eye-to-hand depth vision.
                                    </p>
                                </td>
                            </tr>


                            <!-- Paper 6  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/sucks.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9462388" target="_blank"
                                        <papertitle>Verticalized-Tip Trajectory Tracking of A 3D-Printable Soft
                                        Continuum Robot: Enabling Surgical Blood Suction Automation</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, <a href="https://lu-bo.github.io/" target="_blank">Bo Lu</a>, Qingxiang Zhao, Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME Transactions on Mechatronics (T-MECH)</em>, 2021
                                    <br>
                                    <a href="preprint/TMECH_VT.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/_5zb7vnvwkA" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Configuration constraints on a redundant soft robot,
                                        with rapid IK, solved through point cloud projection and image-based liquid
                                        suction planning.
                                    </p>
                                </td>
                            </tr>

                            <!-- Paper 7  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/aim_demo.gif' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/9158975" target="_blank"
                                        <papertitle>Toward Vision-based Adaptive Configuring of A Bidirectional
                                        Two-Segment Soft Continuum Manipulator</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, <a href="https://lu-bo.github.io/" target="_blank">Bo Lu</a>, and Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics
                                        (AIM)</em>, 2020
                                    <br>
                                    <a href="preprint/10.1109@AIM43001.2020.9158975.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://youtu.be/_yy3LjOx5cc" target="_blank" class="video-button">video</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Steering  and servoing a two-segment soft robot's 2D pose with eye-to-hand vision in real-time - regardless of the static payload.
                                    </p>
                                </td>
                            </tr>

                            
                            <!-- Paper 8  -->
                            <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
                                <td style="padding:2px;width:25%;vertical-align:middle">
                                    <img src='img/robio.png' width="180">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://ieeexplore.ieee.org/document/8961669" target="_blank"
                                        <papertitle>A Learning-based Inverse Kinematics Solver for a Multi-Segment Continuum Robot in Robot-Independent Mapping</papertitle>
                                    </a>
                                    <br>
                                    <strong>Jiewen Lai</strong>,
                                    Kaicheng Huang, and Henry K. Chu*

                                    <!-- <br> -->
                                    <!-- <em>in submission</em> -->
                                    <br>
                                    <em>IEEE International Conference on Robotics and Biomimetics (ROBIO)</em>, 2019
                                    <br>
                                    <a href="preprint/ROBIO_19.pdf" target="_blank" class="pdf-button">pdf</a> 
                                    <a href="https://github.com/jiewen-lai/iksolver_mlx_robio19" target="_blank" class="code-button">code</a> 
                                    <a href="https://research.polyu.edu.hk/en/prizes/best-paper-finalist" target="_blank" class="award-button">best paper finalist award</a> 
                                    <p>
                                        <strong>tl;dr:</strong> Utilizing a lightweight MLP model to learn a redundant soft robot's IK through its simplified DH model.
                                    </p>
                                </td>
                            </tr>



                        </tbody>
                    </table>

                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Professional Memberships</heading>
                                <p>
                                    IEEE Robotics and Automation Society (RAS)<br />
                                    IEEE Industrial Electronics Society (IES)<br />
                                    Chinese Association of Automation (CAA)
                                </p>
                            </td>
                        </tr>
                    </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Professional Services</heading>
                                    <p>
                                        <b>Co-Chair</b>, <a href="https://sites.google.com/view/icra24-c4sr" target="_blank">ICRA 2024 Workshop on <b>C4SR+</b>: Continuum, Compliant, Cooperative, Cognitive Surgical Robotic Systems in the Embodied AI Era</a><br/>
                                        <b>Associate Editor (AE)</b>, <a href="https://2024.ieee-icra.org/" target="_blank">ICRA 2024</a><br/>
                                        <b>Guest Editor</b>, <a href="https://www.mdpi.com/journal/actuators/special_issues/808GZE9H7Y" target="_blank">Actuators</a><br/>
                                        <b>Frequent Reviewer</b>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=3516" target="_blank">IEEE/ASME Transactions on Mechatronics</a><br/>
                                        <b>Frequent Reviewer</b>, <a href="https://www.ieee-ras.org/publications/ra-l" target="_blank">IEEE Robotics and Automation Letters</a><br/>
                                        <b>Reviewer</b>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9424" target="_blank">IEEE Transactions on Industrial Informatics</a>, <a href="https://www.springer.com/journal/11071" target="_blank">Nonlinear Dynamics</a><br/>
                                        <b>Reviewer for conferences</b>, <a href="https://www.ieee-ras.org/conferences-workshops" target="_blank">ICRA, IROS, AIM, ROBIO, CASE, RoboSoft, RCAR, ARM, ICAR</a><br/>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

      

                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Teaching</heading>
                                <p>
                                    <a href="https://www.ee.cuhk.edu.hk/en-gb/curriculum/undergraduate-programme/course-list#Major_Elective_Courses" target="_blank"><b>ELEG4701</b> Intelligent Interactive Robot Practice</a> (2024 Spring) <br>
                                    <a href="preprint/Lab_6__ROS_Navigation___Slides.pdf" target="_blank" class="pdf-button">Lecture 6</a>
                                    <a href="preprint/Lab_9__VS_for_Mobile_Robots.pdf" target="_blank" class="pdf-button">Lecture 9</a>
                                    <a href="preprint/Lab_10__Intro_to_Robot_Arm___Slides.pdf" target="_blank" class="pdf-button">Lecture 10</a> 
                                    
                                </p>
                            </td>
                            
                        </tr>
                    </tbody>
                    </table>


                    <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                                <heading>Some Links</heading>
                                <p>
                                    <a href="http://www.labren.org/mm/" target="_blank"><b>Medical Mechatronics Lab</b></a>, CUHK<br>
                                    <a href="https://www.ucsdarclab.com/" target="_blank"><b>Advanced Robotics and Controls Lab</b></a>, UCSD<br>
                                    <a href="https://hkpfs.erg.cuhk.edu.hk/" target="_blank"><b>Hong Kong PhD Fellowship Summer Workshop</b></a>, Faculty of Engineering, CUHK<br>
                                    <a href="https://link.springer.com/content/pdf/10.1007%2F978-1-84628-642-1.pdf" target="_blank"><b>Robotics: Modelling, Planning and Control</b></a>, Bruno Siciliano et al., Springer's Online Textbook<br>
                                </p>
                            </td>
                            
                        </tr>
                    </tbody>
                    </table>

    <!-- Binance API -->
    <!--<script src="js/binanceAPI.js"></script>-->
    <script>
        function toDecimal2(x) {
            var f = parseFloat(x);
            if (isNaN(f)) {
                return false;
            }
            var f = Math.round(x * 100) / 100;
            var s = f.toString();
            var rs = s.indexOf('.');
            if (rs < 0) {
                rs = s.length;
                s += '.';
            }
            while (s.length <= rs + 2) {
                s += '0';
            }
            return s;
        }

        function toDecimal4(x) {
            var f = parseFloat(x);
            if (isNaN(f)) {
                return false;
            }
            var f = Math.round(x * 10000) / 10000;
            var s = f.toString();
            var rs = s.indexOf('.');
            if (rs < 0) {
                rs = s.length;
                s += '.';
            }
            while (s.length <= rs + 4) {
                s += '0';
            }
            return s;
        }

        var js = document.createElement('script');

        js.onload = function () {
            var p = $("<p id='coin'></p>");

            $(document.body).append(p);

            setInterval(function () {
                $.get("https://api.binance.com/api/v3/ticker/24hr").done(function (data) {
                    /* https://bitpay.com/api/rates */
                    /* https://api.binance.com/api/v3/ticker/price */ /* doesnt work in mainland China */

                    var btc = data[11]
                    var doge = data[558]
                    var eth = data[12]
                    /*  11 and 558 and 12*//////  * 2 52 13/

                    let position = toDecimal2((btc.lastPrice * 0.00396395) * 7.82);
                    let result = position.fontcolor("white");

                    /*  $("#coin").html(" " + (new Date()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) + " | <b>BTC/USD: </b>" + toDecimal2(btc.rate) + " | <b>ETH/USD: </b>" + toDecimal2(btc.rate/eth.rate) + " | <b>DOGE/USD: </b>" + toDecimal4(btc.rate/doge.rate));*/

                    $("#coin").html(" " + (new Date()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) + " | <b>BTC/USDT: </b>" + toDecimal2(btc.lastPrice) + " (" + toDecimal2(btc.priceChangePercent) + "%/24hrs)" + " | " + position);
                });
            }, 5000);

        }
                js.src = "//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js";
                document.head.appendChild(js);
        </script>
            <p><a href="https://bitpay.com/api/rates" target="_blank"><img src="img/btc.png" height="16" /></a> <b>Your local time: </b><p id="coin" style="display: inherit; white-space: nowrap;" align="justify"></p></p>
            <p><small><center>¬© 2021-2024 Jiewen Lai. All Rights Reserved.</center></small></p>
                </td>
                
            </tr>
    </table>
</body>

</html>